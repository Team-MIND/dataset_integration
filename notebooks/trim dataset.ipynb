{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "swedish-heating",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "\n",
    "from sklearn import svm\n",
    "import re\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt\n",
    "import pydicom\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-handbook",
   "metadata": {},
   "source": [
    "## Notebook to trim the dataset from NDA to only the needed files\n",
    "\n",
    "Most of this should be standard except at towards the bottom there are two ways to verify correct files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "interracial-insured",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 2274:\n",
    "path = '../physcosis/Package_1187332/'\n",
    "\n",
    "# should be standard\n",
    "test_file = 'panss01.txt'\n",
    "subject_file = 'ndar_subject01.txt'\n",
    "image_file = 'image03.txt'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stopped-tracy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4404, 26)\n",
      "(4404, 26)\n",
      "(1779, 42)\n",
      "(1779, 42)\n",
      "(9395, 51)\n",
      "(9395, 51)\n"
     ]
    }
   ],
   "source": [
    "# opensfiles using pandas\n",
    "# drop rows that are fully duplicated from the start --> not need \n",
    "ndar_subject = pd.read_csv(os.path.join(path, subject_file), delimiter = '\\t')\n",
    "print(ndar_subject.shape)\n",
    "ndar_subject = ndar_subject.drop_duplicates()\n",
    "print(ndar_subject.shape)\n",
    "test = pd.read_csv(os.path.join(path, test_file), delimiter = '\\t')\n",
    "print(test.shape)\n",
    "test = test.drop_duplicates()\n",
    "print(test.shape)\n",
    "image03 = pd.read_csv(os.path.join(path, image_file), delimiter = '\\t')\n",
    "print(image03.shape)\n",
    "image03 = image03.drop_duplicates()\n",
    "print(image03.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acceptable-restoration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_description\n",
       "ADNI Double_TSE SENSE                                                      561\n",
       "ADNI MPRAGE SENSE                                                           45\n",
       "ADNI MPRAGE pg7 SENSE                                                      516\n",
       "AX T2                                                                       16\n",
       "Axial PD-T2 TSE                                                            118\n",
       "Axial PD-T2 TSE no angle                                                    73\n",
       "Axial PD-T2 TSE_ NO ANGULATION                                               4\n",
       "Axial PD-T2 TSE_NO_ANGLE                                                    26\n",
       "B1-Calibration Body                                                         98\n",
       "B1-Calibration Body_COIL                                                    25\n",
       "B1-Callibration Head                                                        98\n",
       "B1-Callibration Head_COIL                                                   24\n",
       "Bsnip Ax PD-T2 TSE NoAng                                                   290\n",
       "Bsnip Rest 210                                                             244\n",
       "Bsnip Sag MPRAGE-like ADNI                                                 291\n",
       "Bsnip ep2d_diff_MGH-DTI2                                                   755\n",
       "Bsnip ep2d_diff_MGH-DTI2_split_1                                             1\n",
       "DTI                                                                         55\n",
       "DTI-exact repeat of DTI-new                                                271\n",
       "DTI-exact repeat of DTI-new_ADC                                            270\n",
       "DTI-exact repeat of DTI-new_ColFA                                          270\n",
       "DTI-exact repeat of DTI-new_FA                                             270\n",
       "DTI-exact repeat of DTI-new_TENSOR                                          82\n",
       "DTI-exact repeat of DTI-new_TRACEW                                         270\n",
       "DTI-new-12.8.08                                                            273\n",
       "DTI-new-12.8.08_ADC                                                        273\n",
       "DTI-new-12.8.08_ColFA                                                      273\n",
       "DTI-new-12.8.08_FA                                                         273\n",
       "DTI-new-12.8.08_TENSOR                                                      80\n",
       "DTI-new-12.8.08_TENSOR_OFFLINE                                               8\n",
       "DTI-new-12.8.08_TRACEW                                                     273\n",
       "DTI-original                                                                 2\n",
       "DTI-original_ADC                                                             2\n",
       "DTI-original_TRACEW                                                          2\n",
       "DTI_ADC                                                                     55\n",
       "DTI_TRACEW                                                                  55\n",
       "Image description, i.e. DTI, fMRI, Fast SPGR, phantom, EEG, dynamic PET      1\n",
       "MPRAGE                                                                     170\n",
       "MPRAGE Repeat                                                               33\n",
       "MPRAGE_SAG                                                                   3\n",
       "MPRAGE_SAG Repeat                                                            3\n",
       "MPRAGE_repeat                                                               89\n",
       "Mean_&_t-Maps                                                               86\n",
       "MoCoSeries                                                                  33\n",
       "PD-T2 TSE                                                                  329\n",
       "Rest 210                                                                    94\n",
       "SAG B1 CAL 8CH                                                               3\n",
       "SAG B1 CAL BODY                                                              3\n",
       "SAG MPRAGE                                                                 107\n",
       "Sagittal MPRAGE                                                              1\n",
       "Sagittal MPRAGE-like ADNI                                                   65\n",
       "T1 MPRAGE                                                                  339\n",
       "T1 MPRAGE Repeat                                                             5\n",
       "WIP ADNI Double_TSE SENSE                                                  111\n",
       "WIP ADNI MPRAGE pg7 SENSE                                                  114\n",
       "WIP highres T2 SENSE                                                         3\n",
       "WIP rest_fMRI_5min SENSE                                                   114\n",
       "act_MoCoSeries                                                               1\n",
       "bas_MoCoSeries                                                              85\n",
       "ep2d_REST210                                                               118\n",
       "ep2d_bold                                                                  327\n",
       "ep2d_diff_MGH-DTI2                                                          69\n",
       "ep2d_diff_convert_Allegra_B-SNIP                                             3\n",
       "ep2d_diff_convert_Allegra_B-SNIP_ADC                                         3\n",
       "ep2d_diff_convert_Allegra_B-SNIP_ColFA                                       3\n",
       "ep2d_diff_convert_Allegra_B-SNIP_FA                                          3\n",
       "ep2d_diff_convert_Allegra_B-SNIP_TENSOR                                      3\n",
       "ep2d_diff_convert_Allegra_B-SNIP_TRACEW                                      3\n",
       "ep2d_fid_basic_bold                                                          2\n",
       "intermediate t-Map                                                          86\n",
       "loc                                                                         20\n",
       "localizer                                                                  132\n",
       "rest_fMRI_5min SENSE                                                       561\n",
       "resting state fMRI                                                           1\n",
       "sagB1calbody                                                                 5\n",
       "sagb1cal 8ch                                                                14\n",
       "sagb1cal body                                                                8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shows the different types of images available for the data package\n",
    "image03.pivot_table(columns = ['image_description'], aggfunc = 'size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "grateful-elizabeth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scan_type\n",
       "MR diffusion          3882\n",
       "MR structural (T1)    2902\n",
       "MR structural (T2)     977\n",
       "Type of Scan             1\n",
       "fMRI                  1633\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image03.pivot_table(columns = ['scan_type'], aggfunc = 'size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "earned-judge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2902, 51)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image03 = image03[image03['scan_type'].isin(['MR structural (T1)'])]\n",
    "image03.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "incredible-house",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = os.path.join(path, 'image03')\n",
    "\n",
    "#### CHANGE BASED ON WHAT 'image_file' COLUMN LOOKS LIKE IN image03 (corrects the file path to be on local machine) ####\n",
    "\n",
    "# for 2274:\n",
    "regex ='s3://NDAR_.*/submission_.[0-9]*/'\n",
    "\n",
    "\n",
    "rows_with_bad_path = []\n",
    "for index, row in image03.iterrows():\n",
    "    image_path = re.sub(regex, '', row['image_file'])\n",
    "    full_path = os.path.join(data_dir, image_path)\n",
    "#     print(full_path)\n",
    "    if not os.path.exists(full_path):\n",
    "        print(image_path, index, row['image_file'])\n",
    "        rows_with_bad_path.append(index)\n",
    "rows_with_bad_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "expressed-mission",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2902, 51)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drops rows based on rows with bad path and replaces old paths with local paths\n",
    "\n",
    "image03 = image03.drop(rows_with_bad_path)\n",
    "l = []\n",
    "\n",
    "for index, row in image03.iterrows():\n",
    "    image_path = re.sub(regex, '', row['image_file'])\n",
    "    full_path = os.path.join(data_dir, image_path)\n",
    "    l.append(full_path)\n",
    "image03['image_file'] = l\n",
    "image03.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "charged-prefix",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "968\n",
      "Index(['collection_id', 'panss01_id', 'dataset_id', 'subjectkey',\n",
      "       'src_subject_id', 'interview_age', 'sex', 'panss_general',\n",
      "       'panss_negative', 'panss_positive', 'panss_total', 'pos_p1', 'pos_p2',\n",
      "       'pos_p3', 'pos_p4', 'pos_p5', 'pos_p6', 'pos_p7', 'neg_n1', 'neg_n2',\n",
      "       'neg_n3', 'neg_n4', 'neg_n5', 'neg_n6', 'neg_n7', 'gps_g1', 'gps_g2',\n",
      "       'gps_g3', 'gps_g4', 'gps_g5', 'gps_g6', 'gps_g7', 'gps_g8', 'gps_g9',\n",
      "       'gps_g10', 'gps_g11', 'gps_g12', 'gps_g13', 'gps_g14', 'gps_g15',\n",
      "       'gps_g16', 'collection_title'],\n",
      "      dtype='object')\n",
      "(1779, 42)\n",
      "(968, 35)\n"
     ]
    }
   ],
   "source": [
    "# count number of unique subject ids in the panss test \n",
    "print(test['src_subject_id'].nunique())\n",
    "print(test.columns)\n",
    "print(test.shape)\n",
    "# I think only these are needed change is using another test\n",
    "test = test[['src_subject_id', 'interview_age', 'panss_general',\n",
    "       'panss_negative', 'panss_positive', 'pos_p1', 'pos_p2', 'pos_p3',\n",
    "       'pos_p4', 'pos_p5', 'pos_p6', 'pos_p7', 'neg_n1', 'neg_n2', 'neg_n3',\n",
    "       'neg_n4', 'neg_n5', 'neg_n6', 'neg_n7', 'gps_g1', 'gps_g2', 'gps_g3',\n",
    "       'gps_g4', 'gps_g5', 'gps_g6', 'gps_g7', 'gps_g8', 'gps_g9', 'gps_g10',\n",
    "       'gps_g11', 'gps_g12', 'gps_g13', 'gps_g14', 'gps_g15', 'gps_g16']]\n",
    "test.pivot_table(columns = ['src_subject_id', 'interview_age'], aggfunc = 'size')\n",
    "# drop duplicate tests for subjects\n",
    "test = test.drop_duplicates(subset = ['src_subject_id', 'interview_age'])\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "rotary-kennedy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4404, 26)\n",
      "(4404, 26)\n",
      "(2416, 26)\n"
     ]
    }
   ],
   "source": [
    "print(ndar_subject.shape)\n",
    "ndar_subject.pivot_table(columns = ['src_subject_id', 'interview_age'], aggfunc = 'size')\n",
    "print(ndar_subject.shape)\n",
    "ndar_subject = ndar_subject.drop_duplicates(subset = ['src_subject_id', 'interview_age'])\n",
    "print(ndar_subject.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "complex-order",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2822, 75)\n",
      "Index(['collection_id_x', 'image03_id', 'dataset_id_x', 'subjectkey_x',\n",
      "       'src_subject_id', 'interview_age', 'sex_x', 'comments_misc',\n",
      "       'image_file', 'image_description',\n",
      "       ...\n",
      "       'gps_g7', 'gps_g8', 'gps_g9', 'gps_g10', 'gps_g11', 'gps_g12',\n",
      "       'gps_g13', 'gps_g14', 'gps_g15', 'gps_g16'],\n",
      "      dtype='object', length=108)\n",
      "(1341, 108)\n"
     ]
    }
   ],
   "source": [
    "res1 = image03.merge(ndar_subject, on = ['src_subject_id', 'interview_age'], how = 'inner')\n",
    "print(res1.shape)\n",
    "res2 = res1.merge(test,  on = ['src_subject_id', 'interview_age'], how = 'inner')\n",
    "\n",
    "\n",
    "# print(res2['src_subject_id'].nunique())\n",
    "print(res2.columns)\n",
    "print(res2.shape)\n",
    "\n",
    "master_table = res2\n",
    "# master_table.pivot_table(columns = ['src_subject_id', 'interview_age'], aggfunc = 'size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "renewable-material",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_description\n",
       "ADNI Double_TSE SENSE         291\n",
       "ADNI MPRAGE SENSE              36\n",
       "ADNI MPRAGE pg7 SENSE         255\n",
       "B1-Calibration Body            52\n",
       "B1-Calibration Body_COIL       13\n",
       "B1-Callibration Head           51\n",
       "B1-Callibration Head_COIL      13\n",
       "Bsnip Sag MPRAGE-like ADNI    113\n",
       "MPRAGE                         85\n",
       "MPRAGE Repeat                  13\n",
       "MPRAGE_SAG                      2\n",
       "MPRAGE_SAG Repeat               2\n",
       "MPRAGE_repeat                  50\n",
       "SAG B1 CAL 8CH                  2\n",
       "SAG B1 CAL BODY                 2\n",
       "SAG MPRAGE                     22\n",
       "Sagittal MPRAGE                 1\n",
       "Sagittal MPRAGE-like ADNI      17\n",
       "T1 MPRAGE                     168\n",
       "T1 MPRAGE Repeat                2\n",
       "WIP ADNI Double_TSE SENSE      36\n",
       "WIP ADNI MPRAGE pg7 SENSE      36\n",
       "loc                             5\n",
       "localizer                      72\n",
       "sagB1calbody                    1\n",
       "sagb1cal 8ch                    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_table.pivot_table(columns = ['image_description'], aggfunc = 'size')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "filled-bolivia",
   "metadata": {},
   "source": [
    "## Verify Image types\n",
    "\n",
    "If image types are not known, ex. you do not know if an image description in the 'image_description' column is an actual T1 MRI scan, then run the following cells. This will copy one example from each type from the 'image_description' column and move it to a TEST folder and unzip and attempt to convert to niftii. TODO: What do do for non dicomm datasets. \n",
    "\n",
    "\n",
    "\n",
    "If you already are sure of the image types that are needed from the pivot table above, then skip the following 9 cells and enter the good_formats variable in manually. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-doctrine",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Optionally check if all the remaining types can be changed to niftii format properly and filter\n",
    "\n",
    "\n",
    "test_dir = os.path.join(data_dir, 'TEST')\n",
    "\n",
    "if not os.path.exists(test_dir):\n",
    "    os.mkdir(test_dir)\n",
    "test_dir\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aging-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_example = image03.drop_duplicates(subset = ['image_description'], keep='first')\n",
    "single_example.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-tucson",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,row in single_example.iterrows():\n",
    "    file_name = row['image_file'].split('/')[-1]\n",
    "    \n",
    "    folder = os.path.join(test_dir, file_name.split('.')[0])\n",
    "    if not os.path.exists(folder):\n",
    "        os.system('mkdir ' + folder)\n",
    "        os.system('unzip ' + row['image_file'] + ' -d ' + folder)\n",
    "        print('Unziped and moved ', file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-companion",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_path = []\n",
    "for i,row in single_example.iterrows():\n",
    "    folder = row['image_file'].split('/')[-1].split('.')[0]\n",
    "    p = os.path.join(test_dir, folder)\n",
    "    nifti = os.path.join(p, '{}.nii'.format(folder))\n",
    "    if not os.path.exists(nifti):\n",
    "        print('Converting ', folder, ' from dicom to niftii.')\n",
    "        try:\n",
    "            dicom2nifti.dicom_series_to_nifti(p, nifti, reorient_nifti=True)\n",
    "            new_path.append(nifti)\n",
    "        except: \n",
    "            new_path.append('FAILED')\n",
    "            print(folder, ' Failed.')\n",
    "        \n",
    "    else: \n",
    "        new_path.append(nifti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_example['newpath'] = new_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "studied-demographic",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_example = single_example[single_example.newpath != 'FAILED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-lotus",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_formats = list(single_example['image_description'])\n",
    "\n",
    "# manually remove any that we don't need \n",
    "good_formats.remove('ep2d_diff_convert_Allegra_B-SNIP')\n",
    "good_formats.remove('ep2d_diff_convert_Allegra_B-SNIP_ADC')\n",
    "good_formats.remove('ep2d_diff_convert_Allegra_B-SNIP_TRACEW')\n",
    "good_formats.remove('ep2d_diff_convert_Allegra_B-SNIP_FA')\n",
    "\n",
    "\n",
    "good_formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-midnight",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_table = master_table[master_table['image_description'].isin(good_formats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "armed-sodium",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_table = master_table.drop_duplicates(subset = ['src_subject_id', 'interview_age'])\n",
    "master_table.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-murray",
   "metadata": {},
   "source": [
    "### If manually choosing good_format to keep in master table, change the list below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "single-angel",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### manually choose which formats: #####\n",
    "\n",
    "\n",
    "good_formats = ['T1 MPRAGE',\n",
    " 'T1 MPRAGE Repeat',\n",
    " 'MPRAGE Repeat',\n",
    " 'MPRAGE_SAG Repeat',\n",
    " 'Bsnip Sag MPRAGE-like ADNI',\n",
    " 'Sagittal MPRAGE-like ADNI',\n",
    " 'Sagittal MPRAGE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "backed-providence",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_table = master_table[master_table['image_description'].isin(good_formats)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "reflected-distributor",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_table = master_table.drop_duplicates(subset = ['src_subject_id', 'interview_age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "integrated-suite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(301, 108)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_table.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-conviction",
   "metadata": {},
   "source": [
    "### Move the remaining images to a clean folder and save master_table as a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "inclusive-insured",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_dir = os.path.join(data_dir, 'CLEAN')\n",
    "\n",
    "if not os.path.exists(clean_dir):\n",
    "    os.mkdir(clean_dir)\n",
    "\n",
    "\n",
    "new_paths = []\n",
    "for i,row in master_table.iterrows():\n",
    "    \n",
    "    file_name = row['image_file'].split('/')[-1]\n",
    "    os.system('cp -r ' + row['image_file'] + ' ' + os.path.join(clean_dir, file_name))\n",
    "#     print('cp -r ' + row['image_file'] + ' ' + os.path.join(clean_dir, file_name))\n",
    "    new_paths.append(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ambient-cameroon",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_table['image_file'] = new_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "monthly-villa",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_table.to_csv(os.path.join(clean_dir, 'master_table.csv'), sep = '\\t', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-yellow",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
